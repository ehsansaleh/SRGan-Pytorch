{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from skimage import io\n",
    "from skimage.transform import resize, downscale_local_mean\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "\n",
    "from Utilities.data import DataWrapper\n",
    "from Models.SRGanGenerator import Generator\n",
    "from Models.SRGanDiscriminator import Discriminator\n",
    "from Operations.Losses import BCEWithLogitsLoss, SoftMarginLoss, VGGFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x35a9d90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IS_GPU=True\n",
    "RandomSeed = 123456\n",
    "np.random.seed(RandomSeed)\n",
    "torch.cuda.manual_seed_all(RandomSeed)\n",
    "torch.manual_seed(RandomSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = DataWrapper(batch_size=32, random_crop_size=96, down_scale_factor=4, \n",
    "                       root_dir='/mnt/a/u/sciteam/saleh1/work/srgan/Data/TrainingHR',\n",
    "                       loader_shuffle=False, loader_workers=4)\n",
    "\n",
    "evaluation = DataWrapper(batch_size=1, random_crop_size=None, down_scale_factor=4,\n",
    "                         root_dir='/mnt/a/u/sciteam/saleh1/work/srgan/Data/EvaluationHR',\n",
    "                         loader_shuffle=False, loader_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtendedModelWithUtilities(object):\n",
    "    def __init__(self, model_type = 'SRGAN', SRType='MSE', batch_loss_sum_or_mean = 'mean',\n",
    "                 gen_learning_rate = 10 ** -6, beta1 = 0.9, beta2 = 0.999, \n",
    "                 adv2content_loss_ratio = None, disc_learning_rate = None, IS_GPU = True,\n",
    "                 RandomSeed = 123456):\n",
    "        \n",
    "        self.model_type = model_type\n",
    "        self.SRType = SRType\n",
    "        self.batch_loss_sum_or_mean = batch_loss_sum_or_mean\n",
    "        self.gen_learning_rate = gen_learning_rate\n",
    "        if self.model_type == 'SRGAN':\n",
    "            if adv2content_loss_ratio == None:    \n",
    "                self.adv2content_loss_ratio = 10 ** -3\n",
    "            else:\n",
    "                self.adv2content_loss_ratio = adv2content_loss_ratio\n",
    "                \n",
    "            if disc_learning_rate == None:\n",
    "                self.disc_learning_rate = 10 ** -6\n",
    "            else:\n",
    "                self.disc_learning_rate = disc_learning_rate\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.IS_GPU = IS_GPU\n",
    "        self.RandomSeed = RandomSeed\n",
    "        \n",
    "        self.SRTypeDict = {'VGG54': {'i':5, 'j':4, 'net':'vgg19', 'scale':12.75},\n",
    "                           'VGG22': {'i':2, 'j':2, 'net':'vgg19', 'scale':12.75},\n",
    "                           'MSE' : {'scale':1}}\n",
    "        \n",
    "        #Creating the Models\n",
    "        self.CreateModels(gen_arch = {'first_stage_hyperparams' : {'k':9, 'n':64, 's':1}, \n",
    "                                      'residual_blocks_hyperparams' : {'k':3, 'n':64, 's':1, 'B':16}, \n",
    "                                      'upsample_blocks_hyperparams' : {'k':3, 'n':256, 's':1, 'B':2, 'f':2}, \n",
    "                                      'last_stage_hyperparams' : {'k':9, 's':1}},\n",
    "                          \n",
    "                          disc_arch = {'init_ch_expansion' : 64,\n",
    "                                       'B' : 4, \n",
    "                                       'k' : 3,\n",
    "                                       'fcn_kernel' : 6,\n",
    "                                       'dense_nuerons' : [1024]},\n",
    "                          \n",
    "                          SRType = self.SRType)\n",
    "        \n",
    "        #Creating the Optimizers\n",
    "        self.CreateOptimizers()\n",
    "        \n",
    "        #Initializing the Models\n",
    "        self.InitializeModels(RandomSeed = self.RandomSeed)\n",
    "        self.epoch = 0\n",
    "        self.step = 0\n",
    "        \n",
    "        #Transporting to GPU if necessary\n",
    "        if self.IS_GPU:\n",
    "            self.trasnport_models_to_gpu()\n",
    "        \n",
    "        #Defining the losses\n",
    "        self.CreateLosses()\n",
    "        \n",
    "        #Creating Statistics\n",
    "        self.init_step_loss_statistics()\n",
    "        self.init_epoch_loss_statistics()\n",
    "            \n",
    "        \n",
    "                \n",
    "    def CreateModels(self, gen_arch, disc_arch, SRType):\n",
    "        self.ModelRegistry = {}\n",
    "        \n",
    "        self.gen_net = Generator(first_stage_hyperparams = gen_arch['first_stage_hyperparams'], \n",
    "                                 residual_blocks_hyperparams = gen_arch['residual_blocks_hyperparams'], \n",
    "                                 upsample_blocks_hyperparams = gen_arch['upsample_blocks_hyperparams'],\n",
    "                                 last_stage_hyperparams = gen_arch['last_stage_hyperparams'])\n",
    "        self.ModelRegistry['Generator'] = self.gen_net\n",
    "\n",
    "        if self.model_type == 'SRGAN':\n",
    "            self.disc_net = Discriminator(init_ch_expansion = disc_arch['init_ch_expansion'],\n",
    "                                          B = disc_arch['B'],\n",
    "                                          k = disc_arch['k'],\n",
    "                                          fcn_kernel = disc_arch['fcn_kernel'], \n",
    "                                          dense_nuerons = disc_arch['dense_nuerons'])\n",
    "            self.ModelRegistry['Discriminator'] = self.disc_net\n",
    "\n",
    "        if SRType.upper().startswith('VGG'):\n",
    "            self.FeatureExtractor = VGGFeatureExtractor(vggname = self.SRTypeDict[SRType]['net'],\n",
    "                                                   i = self.SRTypeDict[SRType]['i'],\n",
    "                                                   j = self.SRTypeDict[SRType]['j'])\n",
    "            self.ModelRegistry['Feature Extractor'] = self.FeatureExtractor\n",
    "    \n",
    "    def CreateOptimizers(self):\n",
    "        self.GenOptimizer = optim.Adam(self.gen_net.parameters(), lr=self.gen_learning_rate, \n",
    "                                       betas=(self.beta1, self.beta2))\n",
    "        if self.model_type == 'SRGAN':\n",
    "            self.DiscOptimizer = optim.Adam(self.disc_net.parameters(), lr=self.disc_learning_rate, \n",
    "                                            betas=(self.beta1, self.beta2))        \n",
    "\n",
    "            \n",
    "    def InitializeModels(self, RandomSeed = 123456):\n",
    "        if not (RandomSeed == None):\n",
    "            np.random.seed(RandomSeed)\n",
    "            torch.cuda.manual_seed_all(RandomSeed)\n",
    "            torch.manual_seed(RandomSeed)\n",
    "\n",
    "        self.gen_net.apply(self.conv_init)\n",
    "        if self.model_type == 'SRGAN':\n",
    "            self.disc_net.apply(self.conv_init)\n",
    "        \n",
    "    def conv_init(self, m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv') != -1:\n",
    "            init.xavier_uniform(m.weight, gain=np.sqrt(2))\n",
    "            init.constant(m.bias, 0)\n",
    "        elif classname.find('BatchNorm') != -1:\n",
    "            init.constant(m.weight, 1)\n",
    "            init.constant(m.bias, 0)\n",
    "\n",
    "    def count_parameters(self, model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    def trasnport_models_to_gpu(self):\n",
    "        import torch.backends.cudnn as cudnn\n",
    "        \n",
    "        self.gen_net = self.gen_net.cuda()\n",
    "        self.gen_net = torch.nn.DataParallel(self.gen_net, device_ids=range(torch.cuda.device_count()))\n",
    "\n",
    "        if self.model_type == 'SRGAN':\n",
    "            self.disc_net = self.disc_net.cuda()\n",
    "            self.disc_net = torch.nn.DataParallel(self.disc_net, device_ids=range(torch.cuda.device_count()))\n",
    "            \n",
    "        if self.SRType.upper().startswith('VGG'):\n",
    "            self.FeatureExtractor = self.FeatureExtractor.cuda()\n",
    "            self.FeatureExtractor = torch.nn.DataParallel(self.FeatureExtractor, device_ids=range(torch.cuda.device_count()))\n",
    "            \n",
    "        cudnn.benchmark = True\n",
    "    \n",
    "    def CreateLosses(self):\n",
    "        ########################################################################\n",
    "        # Define a Loss function and optimizer\n",
    "        # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "        my_size_average = (self.batch_loss_sum_or_mean == 'mean')\n",
    "        self.NegLogSigmoidProdCriterion = SoftMarginLoss(size_average=my_size_average,reduce=True)\n",
    "        self.BCEWithLogitCriterion = BCEWithLogitsLoss(size_average=my_size_average,reduce=True)\n",
    "        self.MSECriterion = nn.MSELoss(size_average=my_size_average, reduce=True)\n",
    "    \n",
    "    def init_step_loss_statistics(self):\n",
    "        self.step_loss_statistics = {}\n",
    "        \n",
    "        self.step_loss_statistics['Generator Perceptual Loss'] = []\n",
    "        self.step_loss_statistics['Generator Content Loss'] = []\n",
    "        \n",
    "        if self.model_type == 'SRGAN':\n",
    "            \n",
    "            self.step_loss_statistics['Generator Adverserial Loss'] = []\n",
    "            self.step_loss_statistics['Discriminator Total Loss'] = []\n",
    "            self.step_loss_statistics['Discriminator Real Loss'] = []\n",
    "            self.step_loss_statistics['Discriminator Fake Loss'] = []\n",
    "            self.step_loss_statistics['Discriminator Real Logit Output'] = []\n",
    "            self.step_loss_statistics['Discriminator Fake Logit Output'] = []\n",
    "    \n",
    "    def print_step_loss_statistics(self):\n",
    "        information_dict = self.step_loss_statistics\n",
    "        print('Epoch: '+ str(self.epoch) +'\\tStep: ' + str(self.step))\n",
    "        for key in information_dict.keys():\n",
    "            print('\\t' + key + ':\\t\\t\\t' + str(information_dict[key][-1]))\n",
    "        print('-------------------------------------------------')\n",
    "        \n",
    "    def print_epoch_loss_statistics(self):\n",
    "        information_dict = self.epoch_loss_statistics\n",
    "        print('Epoch: '+ str(self.epoch))\n",
    "        for key in information_dict.keys():\n",
    "            print('\\t Average ' + key + ':\\t\\t\\t' + str(information_dict[key]))\n",
    "        print('-------------------------------------------------')\n",
    "            \n",
    "    def init_epoch_loss_statistics(self):\n",
    "        self.epoch_loss_statistics = {}\n",
    "        \n",
    "    def update_epoch_loss_statistics(self):\n",
    "        for key in self.step_loss_statistics.keys():\n",
    "            self.epoch_loss_statistics[key] = np.mean(np.array(self.step_loss_statistics[key]))\n",
    "        \n",
    "    def UpdateDiscriminator(self, SR_im, HR_im):\n",
    "        self.DiscOptimizer.zero_grad()\n",
    "\n",
    "        disc_real_pred_logit = self.disc_net(HR_im)\n",
    "        disc_fake_pred_logit = self.disc_net(SR_im.detach())\n",
    "\n",
    "        disc_real_loss = self.BCEWithLogitCriterion(disc_real_pred_logit, torch.ones_like(disc_real_pred_logit))\n",
    "        disc_fake_loss = self.BCEWithLogitCriterion(disc_fake_pred_logit, torch.zeros_like(disc_fake_pred_logit))\n",
    "\n",
    "        disc_loss = disc_real_loss + disc_fake_loss\n",
    "\n",
    "        disc_loss.backward()\n",
    "        self.DiscOptimizer.step()\n",
    "        \n",
    "        #Reporting the statistics to the class\n",
    "        self.step_loss_statistics['Discriminator Total Loss'].append(disc_loss.data[0])\n",
    "        self.step_loss_statistics['Discriminator Real Loss'].append(disc_real_loss.data[0])\n",
    "        self.step_loss_statistics['Discriminator Fake Loss'].append(disc_fake_loss.data[0])\n",
    "        self.step_loss_statistics['Discriminator Real Logit Output'].append(disc_real_loss.data[0])\n",
    "        self.step_loss_statistics['Discriminator Fake Logit Output'].append(disc_fake_loss.data[0])\n",
    "        \n",
    "    def UpdateGenerator(self, SR_im, HR_im):\n",
    "        self.GenOptimizer.zero_grad()\n",
    "        HR_im = Variable(HR_im.data, volatile=True, requires_grad=False)\n",
    "        if self.model_type == 'SRGAN':\n",
    "            if self.SRType.upper().startswith('VGG'):\n",
    "                HR_features = self.FeatureExtractor(HR_im)\n",
    "                SR_features = self.FeatureExtractor(SR_im)\n",
    "                content_loss_gen = self.MSECriterion(SR_features, HR_features) / (self.SRTypeDict[self.SRType]['scale']**2)\n",
    "            else:\n",
    "                content_loss_gen = self.MSECriterion(SR_im, HR_im)\n",
    "            \n",
    "            disc_fake_pred_logit = self.disc_net(SR_im)\n",
    "            adverserial_loss_gen =  self.NegLogSigmoidProdCriterion(disc_fake_pred_logit, torch.ones_like(disc_fake_pred_logit))\n",
    "            \n",
    "            perceptual_loss_gen = content_loss_gen + adverserial_loss_gen * self.adv2content_loss_ratio\n",
    "        else:\n",
    "            if self.SRType.upper().startswith('VGG'):\n",
    "                HR_features = self.FeatureExtractor(HR_im)\n",
    "                SR_features = self.FeatureExtractor(SR_im)\n",
    "                perceptual_loss_gen = self.MSECriterion(SR_features, HR_features) / (self.SRTypeDict[self.SRType]['scale']**2)\n",
    "            else:\n",
    "                perceptual_loss_gen = self.MSECriterion(SR_im, HR_im)\n",
    "            \n",
    "        perceptual_loss_gen.backward()\n",
    "        self.GenOptimizer.step()\n",
    "        \n",
    "        #Reporting the statistics to the class\n",
    "        self.step_loss_statistics['Generator Perceptual Loss'].append(perceptual_loss_gen.data[0])\n",
    "        if self.model_type == 'SRGAN':\n",
    "            self.step_loss_statistics['Generator Content Loss'].append(content_loss_gen.data[0])\n",
    "            self.step_loss_statistics['Generator Adverserial Loss'].append(adverserial_loss_gen.data[0])\n",
    "        else:\n",
    "            self.step_loss_statistics['Generator Content Loss'].append(perceptual_loss_gen.data[0])\n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printimg2file(np_img, outpath):\n",
    "    curr_img = np_img.reshape(3, np_img.shape[-2], np_img.shape[-1])\n",
    "    curr_img = np.transpose(curr_img,[1,2,0])\n",
    "    curr_img = (curr_img * 255).astype(np.uint8)\n",
    "    io.imsave(outpath , curr_img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = ExtendedModelWithUtilities(model_type = 'SRResNet', SRType='VGG54', batch_loss_sum_or_mean = 'mean',\n",
    "                                   gen_learning_rate = 10 ** -6, beta1 = 0.9, beta2 = 0.999, \n",
    "                                   adv2content_loss_ratio = 10 ** -3, disc_learning_rate = 10 ** -6, IS_GPU = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\tStep: 0\n",
      "\tGenerator Perceptual Loss:\t\t\t0.003315887413918972\n",
      "\tGenerator Content Loss:\t\t\t0.003315887413918972\n",
      "-------------------------------------------------\n",
      "Epoch: 2\tStep: 1\n",
      "\tGenerator Perceptual Loss:\t\t\t0.0031921069603413343\n",
      "\tGenerator Content Loss:\t\t\t0.0031921069603413343\n",
      "-------------------------------------------------\n",
      "Epoch: 2\tStep: 2\n",
      "\tGenerator Perceptual Loss:\t\t\t0.0032140654511749744\n",
      "\tGenerator Content Loss:\t\t\t0.0032140654511749744\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "inconsistent tensor sizes at /dev/shm/cmaclean/python-single/portage/dev-libs/torch-cuda-0.3.0/work/pytorch-0.3.0/torch/lib/THC/generic/THCTensorMath.cu:157",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-f2e65b6f0563>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m                                  \u001b[0mnrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                                  \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                                  scale_each=False, pad_value=0)\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_epoch_loss_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/sciteam/saleh1/.local/lib/python3.5/site-packages/torchvision/utils.py\u001b[0m in \u001b[0;36msave_image\u001b[0;34m(tensor, filename, nrow, padding, normalize, range, scale_each, pad_value)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     grid = make_grid(tensor, nrow=nrow, padding=padding, pad_value=pad_value,\n\u001b[0;32m--> 101\u001b[0;31m                      normalize=normalize, range=range, scale_each=scale_each)\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0mndarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/sciteam/saleh1/.local/lib/python3.5/site-packages/torchvision/utils.py\u001b[0m in \u001b[0;36mmake_grid\u001b[0;34m(tensor, nrow, padding, normalize, range, scale_each, pad_value)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# if list of tensors, convert to a 4D mini-batch Tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# single image H x W\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/bwpy/single/usr/lib/python3.5/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(sequence, dim, out)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor sizes at /dev/shm/cmaclean/python-single/portage/dev-libs/torch-cuda-0.3.0/work/pytorch-0.3.0/torch/lib/THC/generic/THCTensorMath.cu:157"
     ]
    }
   ],
   "source": [
    "EPOCHS=2\n",
    "for epoch in range(EPOCHS):  # loop over the dataset multiple times\n",
    "    Model.init_step_loss_statistics()\n",
    "    Model.step = 0\n",
    "    \n",
    "    for i, data in enumerate(training.loader):\n",
    "        \n",
    "        # get the inputs\n",
    "        HR_im = data['High']\n",
    "        LR_im = data['Low']\n",
    "\n",
    "        if IS_GPU:\n",
    "            HR_im = HR_im.cuda()\n",
    "            LR_im = LR_im.cuda()\n",
    "\n",
    "        # wrap them in Variable\n",
    "        HR_im = Variable(HR_im)\n",
    "        LR_im = Variable(LR_im)\n",
    "        \n",
    "        SR_im = Model.gen_net(LR_im)\n",
    "        \n",
    "        #Discriminator Training\n",
    "        if Model.model_type == 'SRGAN':\n",
    "            Model.UpdateDiscriminator(SR_im, HR_im)\n",
    "            \n",
    "        # Generator Training        \n",
    "        Model.UpdateGenerator(SR_im, HR_im)\n",
    "        \n",
    "        # Print Statistics\n",
    "        Model.print_step_loss_statistics()\n",
    "        Model.step = Model.step + 1\n",
    "        \n",
    "        if i>=2:\n",
    "            break\n",
    "    \n",
    "    eval_out_ims=[]\n",
    "    for i, data in enumerate(evaluation.loader):\n",
    "        HR_im = data['High']\n",
    "        LR_im = data['Low']\n",
    "        \n",
    "        if IS_GPU:\n",
    "            LR_im = LR_im.cuda()\n",
    "\n",
    "        LR_im = Variable(LR_im, requires_grad=False, volatile=True)\n",
    "        SR_im = Model.gen_net(LR_im)\n",
    "        \n",
    "        eval_out_ims.append(torch.squeeze((SR_im.data+1)/2, dim=0))\n",
    "        \n",
    "        printimg2file(np_img = (SR_im.cpu().data.numpy() + 1) / 2,\n",
    "                      outpath = '/mnt/a/u/sciteam/saleh1/work/srgan/Data/GeneratedOutput/Epoch_'+str(epoch)+'_img_'+str(i)+'.png')\n",
    "        \n",
    "    file_name='/mnt/a/u/sciteam/saleh1/work/srgan/Data/GeneratedOutput/Epoch_'+str(epoch)+'_merged.png'\n",
    "    torchvision.utils.save_image(eval_out_ims, file_name, \n",
    "                                 nrow=8, padding=2,\n",
    "                                 normalize=False, range=None,\n",
    "                                 scale_each=False, pad_value=0)\n",
    "    \n",
    "    Model.update_epoch_loss_statistics()\n",
    "    Model.print_epoch_loss_statistics()\n",
    "    Model.epoch = Model.epoch + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
