{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from skimage import io\n",
    "from skimage.transform import resize, downscale_local_mean\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HighResolutionDataset(Dataset):\n",
    "    \"\"\"Preparing High Resolution dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "        \"\"\"\n",
    "        assert os.path.isdir(root_dir), 'Root directory does not exist: '+str(root_dir)\n",
    "        self.root_dir = root_dir\n",
    "        self.imnames=[name for name in os.listdir(self.root_dir) if \n",
    "                      os.path.isfile(os.path.join(self.root_dir, name)) and\n",
    "                     (name.lower().endswith('.png') or name.lower().endswith('.jpg') or\n",
    "                      name.lower().endswith('.bmp') or name.lower().endswith('.tif') or\n",
    "                      name.lower().endswith('.tiff')) ]\n",
    "        assert len(self.imnames)>0, 'No known image types found in the root directory: '+str(root_dir)\n",
    "        self.transform=transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imnames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir,self.imnames[idx])\n",
    "        image = io.imread(img_path)\n",
    "        sample = {'High': image}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image = sample['High']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "        return {'High': image}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AddLowResolution(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        scale_factor (tuple or int): Desired downscaling factor. \n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "        ****The scale_factor and output_size need to be provided mutually exclusive\n",
    "        ****(i.e. exactly one of them should be presented).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, down_scale_factor=4, output_size=None):\n",
    "        assert isinstance(output_size, (int, tuple)) or isinstance(down_scale_factor, int)\n",
    "        if isinstance(down_scale_factor, (int, tuple)):\n",
    "            self.down_scale_factor = down_scale_factor\n",
    "            if isinstance(down_scale_factor, int):\n",
    "                self.down_scale_factor = (down_scale_factor, down_scale_factor)\n",
    "            self.factor_exist=True\n",
    "        else:\n",
    "            self.factor_exist=False\n",
    "            if isinstance(output_size, int):\n",
    "                self.output_size = (output_size, output_size)\n",
    "            else:\n",
    "                assert len(output_size) == 2\n",
    "                self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        hr_image = sample['High']\n",
    "\n",
    "        h, w = hr_image.shape[:2]\n",
    "        if self.factor_exist:\n",
    "            new_h = int(h/self.down_scale_factor[0])\n",
    "            new_w = int(w/self.down_scale_factor[1])\n",
    "            output_shape = (new_h , new_w)\n",
    "        else:\n",
    "            output_shape = self.output_size\n",
    "            \n",
    "        lr_image = resize(hr_image, output_shape, order=1, mode='reflect', \n",
    "                          clip=True, preserve_range=True)\n",
    "        lr_image = np.rint(lr_image).astype(hr_image.dtype)\n",
    "        sample['Low'] = lr_image\n",
    "\n",
    "        return sample\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NormalizeRange(object):\n",
    "    \"\"\"Normalizes the high and low resolution ranges.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_range = (0,255), out_range=(0,1), image_key='Low', out_type = np.float):\n",
    "        assert isinstance(out_range, tuple)\n",
    "        assert isinstance(in_range, tuple)\n",
    "        assert len(out_range) == 2 \n",
    "        assert len(in_range) == 2\n",
    "        \n",
    "        self.out_min = np.float(out_range[0])\n",
    "        self.out_max = np.float(out_range[1])\n",
    "        \n",
    "        self.in_min = np.float(in_range[0])\n",
    "        self.in_max = np.float(in_range[1])\n",
    "        \n",
    "        #Output = m * Input + b\n",
    "        self.m = (self.out_max - self.out_min)/(self.in_max - self.in_min)\n",
    "        self.b = self.out_min - self.m * self.in_min\n",
    "        \n",
    "        self.image_key = image_key\n",
    "        self.out_type = out_type\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image = sample[self.image_key]\n",
    "\n",
    "        out_image = image.astype(np.float) * self.m + self.b\n",
    "        out_image = out_image.astype(self.out_type)\n",
    "        \n",
    "        sample[self.image_key] = out_image\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        \n",
    "        for curr_attr in sample.keys():\n",
    "            \n",
    "            curr_val=sample[curr_attr]\n",
    "            \n",
    "            if curr_attr=='High' or curr_attr=='Low':\n",
    "                # swap color axis because\n",
    "                # numpy image: H x W x C\n",
    "                # torch image: C X H X W\n",
    "                sample[curr_attr] = torch.from_numpy( curr_val.transpose((2, 0, 1)) )\n",
    "            else:\n",
    "                sample[curr_attr] = torch.from_numpy( curr_val )\n",
    "                \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataWrapper(object):\n",
    "    \"\"\"Creates a dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, batch_size=32, random_crop_size=96, down_scale_factor=4, \n",
    "                 root_dir='/u/sciteam/saleh1/work/srgan/Data/HighResolution',\n",
    "                 loader_shuffle=True, loader_workers=4):\n",
    "        self.batch_size = batch_size\n",
    "        self.root_dir=root_dir\n",
    "        self.loader_shuffle=loader_shuffle\n",
    "        self.loader_workers=loader_workers\n",
    "        \n",
    "        transform_list=[]\n",
    "        if random_crop_size:\n",
    "            transform_list.append(RandomCrop(random_crop_size))\n",
    "        \n",
    "        transform_list.append(AddLowResolution(down_scale_factor=down_scale_factor))\n",
    "        \n",
    "        transform_list.append(NormalizeRange(in_range = (0,255), out_range=(0,1),\n",
    "                                             image_key='Low', out_type = np.float))\n",
    "        \n",
    "        transform_list.append(NormalizeRange(in_range = (0,255), out_range=(-1,1),\n",
    "                                             image_key='High', out_type = np.float))\n",
    "        \n",
    "        transform_list.append(ToTensor())\n",
    "        \n",
    "        self.full_transform = transforms.Compose(transform_list)\n",
    "        \n",
    "        \n",
    "        self.dataset = HighResolutionDataset(root_dir=self.root_dir, transform = self.full_transform)\n",
    "        \n",
    "        self.loader = torch.utils.data.DataLoader(self.dataset,\n",
    "                                                  batch_size=self.batch_size,\n",
    "                                                  shuffle=self.loader_shuffle,\n",
    "                                                  num_workers=self.loader_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training=DataWrapper()\n",
    "#for i_batch , sample_batch in enumerate(training.dataset):\n",
    "#    print((sample_batch))\n",
    "#    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
